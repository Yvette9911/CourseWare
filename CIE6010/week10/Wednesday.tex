\section{Wednesday}\index{week2_Wednesday_lecture}
\[
\begin{array}{ll}
\min&f(\bm x)\\
&h(\bm x)=0\\
&\bm x\in X\subseteq\mathbb{R}^n
\end{array}
\]
The augmented Lagrangian function is given by:
\[
L_{\bm c}(\bm x,\bm\lambda)=f(\bm x)+\bm\lambda\trans h(\bm x)+\frac{\bm c}{2}\|h(\bm x)\|^2
\]
\paragraph{Quadratic Penalty (Courant, 1943)} 
\begin{align*}
\bm x^r&=\arg\min_{\bm x\in X} L_{\bm c^r}(\bm x,\bm\lambda^r,\bm c^r)\\
&\mbox{increase $\bm c^{r+1}>\bm c^r$}\to\infty,\qquad
\|\bm\lambda^r\|<+\infty
\end{align*}

\paragraph{Augmented Lagrangian Multiplier Method}
\begin{align*}
\bm x^r&=\arg\min_{\bm x\in X}L_{\bm c}(\bm x,\bm\lambda^r)\\
\bm\lambda^{r+1}&=\bm\lambda^r+\bm c h(\bm x)
\end{align*}
where $\bm c$ is sufficiently large in general, but not goes to infinite.
\begin{example}
Given problems
\[
\begin{array}{ll}
\min&\frac{1}{2}(-x_1^2+x_2^2)\\
&x_1=1
\end{array}
\]
with optimal solution $\bm x^*=(1,0);\lambda^*=1$. The Lagrangian function is given by:
\[
L_c(\bm x,\lambda)=\frac{1}{2}(-x_1^2+x_2^2)+\lambda(x_1-1)+\frac{c}{2}(x_1-1)^2,
\]
with
\[
\nabla_{\bm x}L_c=\begin{pmatrix}
-x_1\\x_2
\end{pmatrix}+[\lambda+c(x_1-1)]\begin{pmatrix}
1\\0
\end{pmatrix}=\begin{pmatrix}
0\\0
\end{pmatrix}
\]
Question: Why $\nabla_{\bm x}L_c=\bm0$ to be the necessary condition?
\[
\bm x=\begin{pmatrix}
\frac{c-\lambda}{c-1}\\0
\end{pmatrix}
\]
Also,
\[
\nabla_{\bm{xx}}^2L_c=\begin{pmatrix}
c-1&0\\0&c+1
\end{pmatrix}
\]
Comments on the change of $c$ and $\lambda$.
\end{example}
\paragraph{Optimality condtion for orign problem}
\[
\nabla_{\bm x}L_{\bm c}(\bm x,\lambda)=
\nabla f(\bm x)
+
\nabla h(\bm x)\lambda+c\nabla h(\bm x)h(\bm x)
=
\nabla f(\bm x)
+
\nabla h(\bm x)(\bm\lambda+ch(\bm x))
\]
If $c\to\infty,$ then $h(\bm x)\to\bm0$


















