
\chapter{Week10}
\section{Monday}\index{week2_Tuesday_lecture}
\paragraph{Announcement}
No assignment in this week, so you may take a break. However, in next week new assignments and projects will be updated, which requires you to apply penalty algorithms.
\subsection{Duality Theory}
Firstly, we introduce the Farka's lemma, which plays a significant role in the proof of KKT condition:
\begin{theorem}[Farka's Lemma]
Let $\bm A\in\mathbb{R}^{m\times n}$ and $\bm b\in\mathbb{R}^m$, then exactly one of the following are true:
\begin{enumerate}
\item
There exists $\bm x\in\mathbb{R}^n$ such that $\bm{Ax}=\bm b$ and $\bm x\ge0$
\item
There exists $\bm y\in\mathbb{R}^m$ such that $\bm A\trans\bm y\ge0$ and $\bm b\trans\bm y<0$
\end{enumerate}
\end{theorem}
The proof follows from the duality of linear programming.
\begin{remark}
Define the \emph{polar cone} to be $C(\bm A)=\{\bm{Ax}\mid \bm x\ge0\}$. Then the interpreation of this theorem is that either thet given vector $\bm b$ is in the polar cone of $\bm A$, or otherwise we can find a linear function $\bm y$ such that $\bm b$ is separated from $C(\bm A)$, i.e., there exists a vector $\bm y$ that is normal to all row vectors $\bm a_i$ of $\bm A$, but the angle between $\bm y$ and $\bm b$ is at most $90^{\circ}$.
\end{remark}

\paragraph{Convex Program}
Consider the convex problem below
\begin{equation}\label{Eq:10:1}
\begin{array}{ll}
\min&f(x)\\
\mbox{such that}&\bm{Ax}=\bm b\\
&g(\bm x)\le0
\end{array}
\end{equation}
where $f,g$ are both convex. The Lagrangian function is given by:
\[
L(\bm x,\bm\lambda,\bm\mu)=f(\bm x)+\bm\lambda(\bm{Ax}-\bm b)+\bm\mu\trans g(\bm x),
\qquad
\bm\mu\ge0
\]
It is clear that the Lagrangian function is convex in $\bm x$. Therefore the dual function is convex as well:
\[
Q(\bm\lambda,\bm\mu)=\inf_{\bm x,\bm\mu\ge0}L(\bm x,\bm\lambda,\bm\mu)
\]
\begin{proposition}[Weak Deality]
\[
Q(\bm\lambda,\bm\mu)\le f(\bm x)
\]
for dual feasible $\bm\lambda,\bm\mu$ and primal feasible $\bm x$.
\end{proposition}
We are curious on the tightest lower bound on LHS, thus we maximize the dual function to obtain the dual program:
\begin{equation}
\begin{array}{ll}
\max&Q(\bm\lambda,\bm\mu)\\
\mbox{such that}&\bm\mu\ge0
\end{array}
\end{equation}
\begin{proposition}[Strong Duality]
For convex problem (\ref{Eq:10:1}) with the \emph{constraint qualification}, we have
\[
d^*=p^*,
\]
with $d^*,p^*$ to be the optimal value from dual and primal problems, respectively.
\end{proposition}
\begin{remark}
The constraint qualification means that one of the following conditions has to be satisfied
\begin{itemize}
\item
Linear constraint qualification: $g(\bm x)$ is linear function
\item
Slater's condition: there exists one feasible $\bm x$ such that one component of $g(\bm x)$ is strictly negative.
\item
Regularity: The gradients of the active inequality constraints and the gradients of the equality constraints are linearly independent at the optimizer.
\end{itemize}
\end{remark}

Under the constraint qualification, furthermore, the primal and dual could attain optimality togethoer iff
\begin{itemize}
\item
$\bm{Ax}=\bm b,g(\bm x)\le0$
\item
$\bm\mu\ge0$
\item
$\bm\mu\circ g(\bm x)=\bm0$
\end{itemize}
Now we study the dual formula for quadratic programming:
\begin{example}
For simlicity, let's study a strictly convex problem
\begin{equation}
\begin{array}{ll}
p^*=\min&\frac{1}{2}\bm x\trans\bm Q\bm x+\bm c\trans\bm x,\quad\bm Q\succ0\\
\mbox{such that}&\bm{Ax}\le\bm b
\end{array}
\end{equation}
The Lagrangian function $L(\bm x,\bm\mu)=\frac{1}{2}\bm x\trans\bm Q\bm x+\bm c\trans\bm x+\bm\mu\trans(\bm{Ax}-\bm b)$, and therefore
\begin{equation}\label{Eq:10:3}
Q(\bm\mu)=\min_{\bm x,\bm\mu\ge0}L(\bm x,\bm\mu)
\end{equation}
The optimality condition implies that
\[
\nabla_{\bm x}L(\bm x,\bm\mu)=\bm{Qx}+\bm c+\bm A\trans\bm\mu=0\implies
\bm x=-\bm Q^{-1}(\bm c+\bm A\trans\bm\mu)
\]
Thus substituting optimal $\bm x$ into (\ref{Eq:10:3}), we derive
\begin{align*}
Q(\bm\mu)&=-\frac{1}{2}\bm\mu\trans\bm A\bm Q^{-1}\bm A\trans\bm\mu-\bm t\trans\bm\mu+\mbox{constant}
\end{align*}
Thus we derive the dual program:
\begin{equation}
\begin{array}{ll}
d^*=\min&\frac{1}{2}\bm\mu\trans\bm P\bm\mu+\bm t\trans\bm\mu,\\
\mbox{such that}&\bm\mu\ge0
\end{array}
\end{equation}
where $\bm P:=\bm A\bm Q^{-1}\bm A\trans$.
\end{example}
The deviation for strictly convex quadratic programming is simple. In the final project you may required to solve a non-convex quadratic programming problem. However, even a slightly slightly non-convex part for such problem is super-difficult to handle.
\subsection{Penalty Algorithms}
The practical optimization algorithms are based on penalty. Let's introduce them systematically.
\paragraph{Logarithm Penalty}
Consider the inequality constraint problem
\begin{equation}\label{Eq:10:6}
\begin{array}{ll}
\min&f(\bm x)\\
&g_i(\bm x)\le0
\end{array}
\end{equation}
We introduce a penalty to approximate the original problem with an unconstraint barrier problem:
\begin{equation}\label{Eq:10:7}
\min f(x)-\mu\sum_{i}\log(-g_i(\bm x)),\quad\mu>0
\end{equation}
As $\mu\to0$, the optimal solution to (\ref{Eq:10:7}), say $x^*(\mu)$ converges to the optimal solution to (\ref{Eq:10:6}). For pratical usage, we pick big $\mu$ at first to save computation resource and obtain a relatively good initial guess, and then gradually decrease $\mu$.
\paragraph{Quadratic Penalty}
For the constraint problem
\begin{equation}
\begin{array}{ll}
\min&f(\bm x)\\
&h(\bm x)=0\\
\end{array}
\end{equation}
The quadratic penalty algorithm aims to solve the unconstaint problem with parameters $\lambda$ and $c$:
\begin{equation}\label{Eq:10:9}
\begin{array}{ll}
\min&f(\bm x)+\lambda\trans h(\bm x)+\frac{c}{2}\|h(\bm x)\|_2^2\\
\end{array}
\end{equation}
with $\lambda$ to be \emph{bounded}. There are generally two approaches to solve this problem:
\begin{enumerate}
\item
Take $c\to\infty$, then the optimal solution of (\ref{Eq:10:9}) will converge to the original one. We pick small $c$ at first and obtain a good initial guess, and then we continus to increase $c$. This is so called the traditional \emph{quadratic penalty method}.
\item
Apply the optimality condition of (\ref{Eq:10:9}) to obtain the Lagrange multiplier of the optimal solution, say $\lambda^*$. Then for a large $c$ (not necessarily goes to infinite), take $\lambda\to\lambda^*$, then the optimal solution of (\ref{Eq:10:9}) will converge to the original one as well. This is so called the \emph{Lagrangian Multiplier Method}.
\end{enumerate}
\begin{example}
Consider the convex problem
\[
\begin{array}{ll}
\min&\frac{1}{2}(x_1^2+x_2^2)\\
&x_1=1
\end{array}
\]
we obtain the quadratic penalty function is 
\[
L_c(x)=\frac{1}{2}(x_1^2+x_2^2) + \lambda(x_1-1)+\frac{c}{2}(x_1-1)^2
\]
The necessary optimality condition gives
\[
\nabla_{\bm x}L_c(\bm x)=\begin{pmatrix}
x_1\\x_2
\end{pmatrix}+\lambda\begin{pmatrix}
1\\0
\end{pmatrix}+c\begin{pmatrix}
x_1-1\\0
\end{pmatrix}=\begin{pmatrix}
0\\0
\end{pmatrix},\implies
\left\{\begin{aligned}
x_1^*(\lambda,c)&=\frac{c-\lambda}{c+1},\\
x_2^*(\lambda,c)&=0
\end{aligned}\right.
\]

We can apply two algorithm to solve this problem:
\begin{enumerate}
\item
Taking $c\to\infty$ with $\lambda$ bounded, we derive $x_1^*(\lambda,c)\to1$.
\item
Apply necessary optimality condition $\nabla L(\bm x,\lambda)=0$ to obtain $\lambda^*=-1$. Taking $\lambda\to\lambda^*$, we obtain $x_1(\lambda,c)\to1$ for $c>1$.
\end{enumerate}
\end{example}
Such an algorithm can also be applied for the non-convex problem, e.g.,
\[
\begin{array}{ll}
\min&\frac{1}{2}(-x_1^2+x_2^2)\\
&x_1=1
\end{array}
\]













