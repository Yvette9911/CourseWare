\chapter{Week14}

\section{Monday}\index{week6_Tuesday_lecture}

\paragraph{Notation}The inner product $\inp{\bm X}{\bm Y}$ is defined as:
\[
\inp{\bm X}{\bm Y}=\sum_{i,j=1}^nx_{ij}y_{ij}=\mbox{trace}(\bm X\trans\bm Y)
\]
The conic programming aims to optimize
\begin{equation}
\begin{array}{ll}
\min&\inp{\bm C}{\bm X}\\
&\bm{AX}=\bm b\\
&\bm X\in\mathcal{K}
\end{array}
\end{equation}
where $\mathcal{K}$ is a \emph{convex closed pointed cone}. The pointed cone is a cone that contains no line (from $-\infty$ to $\infty$ is called a line).

\begin{enumerate}
\item
For the linear programming, $\mathcal{K}=\mathbb{R}^n_+=\{\bm x\in\mathbb{R}^n\mid\bm x\ge0\}$
\item
For the SOCP, $\mathcal{K}=\mathcal{S}_2^{n+1}=\{(\xi,\bm X)\mid \xi\ge\|\bm X\|\}$
\item
For the semidefinite programming, $\mathcal{K}=\{\bm X\in\mathbb{R}^{n\times n}\mid\bm X=\bm X\trans\succeq0\}$
\end{enumerate}
\begin{definition}[Dual cone]
The dual cone is defined as
\[
\mathcal{K}^*=\{\bm X\mid\inp{\bm X}{\bm Y}\ge0,\forall Y\in\mathcal{K}\}
\]
\end{definition}
\begin{proposition}
For LP, SOCP, SDP, the dual cone $\mathcal{K}^*=\mathcal{K}$.
\end{proposition}
\begin{proof}
We pick the SDP case as an example.
\begin{enumerate}
\item
We show $\mathcal{K}\subseteq\mathcal{K}^*$ first. 

For $\bm S\in\mathcal{K}$, we have 
\begin{align*}
\bm S=\bm U\bm\Lambda\bm U\trans
&:=
\bm U\bm\Lambda^{1/2}\bm\Lambda^{1/2}\bm U\trans\\
&=(\bm U\bm\Lambda^{1/2}\bm U\trans)(\bm U\bm\Lambda^{1/2}\bm U\trans)\\
&:=\bm S^{1/2}\bm S^{1/2}
\end{align*}
It suffices to show that the inner product between $\bm S$ and any other elements in $\mathcal{K}$ is non-negative:
\[
\inp{\bm S}{\bm X}=\trace(\bm S\bm X)=\trace(\bm S^{1/2}\bm S^{1/2}\bm X)=\trace(\bm S^{1/2}\bm X\bm S^{1/2})\ge0,
\]
the last inequality is because $\bm S^{1/2}\bm X\bm S^{1/2}$ is psd and the operator $\trace(\cdot)$ outputs the sum of eigenvalues.
\item
Let $\bm Y\in\mathcal{K}^*$, and any element $\bm V\bm V\trans\in\mathcal{K}$, we have
\[
\inp{\bm Y}{\bm V\bm V\trans}=\trace(\bm Y\bm V\bm V\trans)=\trace(\bm V\trans\bm Y\bm V)=\bm V\trans\bm Y\bm V\ge0,
\]
where the last inequality is because $\bm V\trans\bm Y\bm V$ is a scalar. Therefore, $\bm Y\in\mathcal{K}$, and $\mathcal{K}^*=\mathcal{K}$.
\end{enumerate}
\end{proof}
The self-dual properites allows us to apply the primal-dual interior method to solver the conic programming.

\paragraph{Dual programming}
\begin{equation}
\begin{array}{ll}
\max&\bm b\trans\bm y\\
&\bm A\Her\bm y+\bm S=\bm C\\
&\mathcal{S}\in\mathcal{K}^*
\end{array}
\end{equation}
For SDP, 
\[
\bm{AX}=\bm b,
\]
where $\bm A:\mathbb{R}^{n\times n}\to\mathbb{R}^m$ and $\bm A\Her:\mathbb{R}^m\to\mathbb{R}^{n\times n}$ are linear operators. The pair $(\bm A,\bm A\Her)$ admits the property
\[
\inp{\bm{AX}}{\bm y}=\inp{\bm X}{\bm A\Her\bm y}
\]

\begin{example}[Primal-SDP]
Suppose we want to optimize
\begin{equation}
\begin{array}{ll}
\min&\inp{\bm C}{\bm X}\\
&\bm{A}_i{X}=\bm b_i,\quad i=1,\dots,m\\
&\bm X\succeq0
\end{array}
\end{equation}
for
\[
\begin{array}{ll}
\bm C=\begin{pmatrix}
0&0&0\\0&0&0\\0&0&1
\end{pmatrix},
&
\bm A_1=\begin{pmatrix}
1&0&0\\0&0&0\\0&0&0
\end{pmatrix}\\
\bm A_2=\begin{pmatrix}
0&1&0\\1&0&0\\0&0&2
\end{pmatrix},
&
\bm b=\begin{pmatrix}
0\\2
\end{pmatrix}
\end{array}
\]
This problem can be transformed into
\begin{equation}
\begin{array}{ll}
\min&x_{33}\\
&x_{11}=0\\
&2x_{12}+2x_{33}=2\\
&X\succeq0
\end{array}
\end{equation}
After computation, we obtain the optimal solution
\[
\begin{pmatrix}
0&0&\times\\0&x_{22}&\times\\\times&\times&1
\end{pmatrix}\succeq0
\]
with the optimal value $1$.

Next we try to solve the dual SDP:
\[
\begin{array}{ll}
\max&2y_2\\
&y_1\begin{pmatrix}
1&0&0\\0&0&0\\0&0&0
\end{pmatrix}+y_2\begin{pmatrix}
0&1&0\\1&0&0\\0&0&2
\end{pmatrix}\preceq\begin{pmatrix}
0&0&0\\0&0&0\\0&0&1
\end{pmatrix}
\end{array}
\]
Or equivalently, the constraint should be
\[
\begin{pmatrix}
-y_1&-y_2&0\\-y_2&0&0\\0&0&1-2y_2
\end{pmatrix}\succeq0
\]
After computation, we obtain the optimal value $y_2=0$.
\end{example}

\begin{remark}
The strong duality does not necessarily hold for conic programming.
\end{remark}









