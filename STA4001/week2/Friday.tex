
%\chapter{Week2}

\section{Thursday}\index{week2_Friday_lecture}
Earning $\&$ learning
\subsection{Discrte Time Markov Chains}
Given 
\begin{itemize}
\item
time index $T=\{0,1,2,\dots\}$
\item
discrte set of states (alphabet): $\mathcal{S}$
\item
$X_n$ denotes the state at time $n$
\item
Transition probabilities (Time homogeneous):
\[
\begin{array}{ll}
P_{ij} = \mathbb{P}\{X_{n+1} = j\mid X_n = i\}
&
i,j\in\mathcal{S}
\end{array}
\]
\end{itemize}
$X = \{X_n: n=0,1,\dots\}$ satisfies the Markov property, i.e., for each $n\ge 1$ for $i_0,i_1,\dots,i,j\in\mathcal{S}$,
\[
\mathbb{P}\{X_{n+1} = j\mid X_n = i, X_0 = i_0,X_1 = i_1,\dots,X_{n-1} = i_{n-1}\}  = P_{ij}
\]
Given the current information, the past information is irralevant for future information.

\paragraph{Example 1: simple random walk}
Suppose toss a coin at each time, and you go right if get a head; go left if get a tail. $i$ denotes the location. We have the conditional probability
\[
\mathbb{P}\{X_{n+1}=i+1\mid X_n = i,X_{n-1},\dots,X_0\}
=
\mathbb{P}\{X_{n+1}=i+1\mid X_n = i\}=p
\]
In this case the transition probability matrix has infinite dimension. 

Given $\mathcal{S}=\{0,1\}$ and the transition probability matrix
\[
P=\begin{pmatrix}
\alpha&1-\alpha\\1 - \beta&\beta
\end{pmatrix}=\begin{pmatrix}
3/4&1/4\\1/2&1/2
\end{pmatrix}
\]

\begin{theorem}
Given a function
\[
\begin{array}{ll}
f:(i,u)\in\mathcal{S}\times\mathbb{R}^+,
&
f(i,u)\in\mathcal{S}
\end{array}
\]
$\{U_n: n=1,2,\dots\}$ is an i.i.d. sequence. $X_{n+1} = f(X_n,U_{n+1})$. Then $\{X_n: n=1,2,\dots\}$ is a DTMC.
\end{theorem}

\paragraph{Application 1}
Suppose $U_n$ is a coin toss at time $n$, i.e., 
\[
\begin{array}{ll}
\mathbb{P}(U_n = 1) = p,
&
\mathbb{P}(U_n = -1) = q
\end{array}
\]
and define $f: (i,u)\in\mathbb{Z}\times\{-1,1\} = i+u\in\mathbb{Z}$













