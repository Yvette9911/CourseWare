%\chapter{Introduction to Linear Programming}
\chapter{The KKT Condition for Nonlinear Programming}

\section{unconstrained Optimality Condition}
Consider the unconstrained optimization
\begin{equation}
\begin{array}{ll}
\min&f(x)
\end{array}
\end{equation}
where $f:\mathbb{R}^n\to\mathbb{R}$ is an $m$-th order \emph{continuously differentiable} function. We aim to find the optimality condition for this problem.

\begin{theorem}[First Order Necessary Condition]
Given the condition that $f\in\mathcal{C}^1$, if $x^*$ is a local minimum point, then $\nabla f(x^*)=0$.
\end{theorem}
\begin{theorem}[Second Order Necessary Condition]
Given the condition that $f\in\mathcal{C}^2$, if $x^*$ is a local minimum point, then $\nabla f(x^*)=0$ and $\nabla^2f(x^*)\succeq0$.
\end{theorem}

\begin{theorem}[Second Order Sufficient Condition]
Given the condition that $f\in\mathcal{C}^2$, if $\nabla f(x^*)=0$ and $\nabla^2f(x^*)\succ0$, then $x^*$ is a local minimum point.
\end{theorem}

\begin{theorem}[First Order Necessary and Sufficient Condition]
If $f$ is convex, then $x^*$ is a local minimum point if and only if $0\ni\partial f(x^*)$.
\end{theorem}

\begin{proof}
All theorems above relies on the Taylor expansion and 
\[
f(x^*+\Delta x)\ge f(x^*),\forall\Delta x
\Longleftrightarrow
\text{the point $x^*$ is minimum}
\]
\end{proof}

All the conditions above only involve the explicit quantities related to $x$. Now we turn into the constrained optimization case.

\section{Constrained Optimality Condition}
Consider the special constrained optimization
\begin{equation}\label{Eq:4:2}
\begin{array}{ll}
\min&f(x)\\
\mbox{such that}&x\in\mathcal{X}\\
\end{array}
\end{equation}
where $\mathcal{X}\subseteq\mathbb{R}^n$ is usually pre-assumed to be a closed convex set.

\begin{definition}[Tangent Cone]
Let $\hat x\in\mathcal{X}$. The \emph{tangent cone} of $\mathcal{X}$ at point $\hat x$ is defined as
\[
\mathcal{T}(\hat x):=\left\{
y\ne0\middle|\exists x^k\in\mathcal{X}:\
x^k\to\hat x\
\&\
\frac{x^k-\hat x}{\|x^k-\hat x\|}\to\frac{y}{\|y\|}
\right\}\cup\{0\}
\]
It's clear that $\mathcal{T}(\hat x)$ denotes all feasible directions from $\hat x$ within $\mathcal{X}$
\end{definition}

Therefore we obtain a necessary optimality condition for constrained optimization, which is beautiful in theory but not that useful in practice:
\begin{theorem}[First Order Necessary Condition]\label{The:4:5}
If $x^*$ is a local minimum point for the constraint (neither necessarily convex nor closed) set $\mathcal{X}$, then
\[
\inp{\nabla f(x^*)}{y}\ge0,\ \forall y\in\mathcal{T}(x^*),
\]
i.e., $\nabla f(x^*)\in(\mathcal{T}(x^*))^*$.
\end{theorem}
\begin{theorem}
The above condition becomes necessary and sufficient if $f$ is convex. In that case, we may weaken the condition into
\[
\partial f(x^*)\cap (\mathcal{T}(x^*))^* \ne\emptyset.
\]
\end{theorem}

\begin{proof}
The proof relies on the fact that $f$ is convex iff
\[
f(y)\ge f(x)+\inp{d}{(y-x)},\forall x,y\in\mathcal{X},
\]
where $d\in\partial f(x^*)$.
\end{proof}

\begin{theorem}\label{The:4:7}
Given further condition that $\mathcal{X}$ is a convex set, if $x^*$ is a local minimum point for the constraint set $\mathcal{X}$, then
\[
\inp{\nabla f(x^*)}{y-x^*}\ge0,\ \forall y\in\mathcal{X}.
\]
This condition becomes sufficient if $f$ is convex.
\end{theorem}

\subsection{Characteration of Tangent Cone}
\begin{enumerate}
\item
Consider the polyhedral constraint set
\[
\mathcal{X}=\{x\mid a_i\trans x\le b_i,\ i=1,\dots,m\}
\]
Let $\hat x\in\mathcal{X}$, and $I(\hat x)=\{i\mid a_i\trans \hat x=b_i\}$. Then we have
\[
\mathcal{T}(\hat x) = \{d\mid a_i\trans d\le0,\ \forall i\in I(\hat x)\}.
\]
\item
Consider another more general constraint set
\[
\mathcal{X}=\left\{x\middle|
\begin{aligned}
h_i(x) &= 0,\ i=1,\dots,m;\\
g_j(x) &\le0,\ j=1,\dots,r
\end{aligned}\right\}.
\]
For $\hat x\in\mathcal{X}$, define $I(\hat x) = \{j\mid g_j(\hat x)=0\}$ likewise.
Let's introduce a easily computable cone
\[
\mathcal{C}(\hat x) =\left\{d\middle|
\begin{aligned}
\inp{\nabla h_i(\hat x)}{d}&= 0,\ i=1,\dots,m;\\
\inp{\nabla g_j(\hat x)}{d} &\le0,\ \forall j\in I(\hat x)
\end{aligned}\right\}.
\]
It's clear that $\mathcal{T}(\hat x)\subseteq\mathcal{C}(\hat x)$. However, in general $\mathcal{T}(\hat x)\ne \mathcal{C}(\hat x)$. (Consider $\mathcal{X} = \{(x_1,x_2)\mid x_1\ge0,x_2^2\le0\}$).

A popular condition to ensure the equality is the \emph{Linear Independence Constraint Qualification} (LICQ):
\begin{quotation}
The vectors
$
\nabla h_i(x),\ i=1,\dots,m;
\nabla g_j(x), \ j\in I(x)
$
are always linearly independent for $\forall x\in\mathcal{X}$.
\end{quotation}

\begin{theorem}
Under the LICQ, if the functions $h_i,g_j$ are differentiable with Lipschitz continuous gradient, then $\mathcal{T}(\hat x)=\mathcal{C}(\hat x)$.
\end{theorem}
\begin{proof}
Consider the case for which $\mathcal{X}$ does not have equality constraints. Take $d\in\mathcal{C}(\hat x)$. Applying LICQ and Theorem~(\ref{The:2:7}), there exists $\hat d$ such that
\[
\inp{\nabla g_i(\hat x)}{\hat d}<0,\ i\in I(\hat x).
\]

Consider $x(t) = \hat x+ td+t^{1.5}\hat d$, we imply 
\[
g_i(x(t))<0,\ i\in I(\hat x),\text{ for }0<t<\varepsilon,
\]
where $\varepsilon>0$ is sufficiently small. Therefore, $d\in\mathcal{T}(\hat x)$.
\end{proof}
\end{enumerate}


\subsection{The KKT Condition}
The optimization problem below admits another type of optimality condition:
\begin{equation}\label{Eq:4:3}
\begin{array}{ll}
\min&f(x)\\
\mbox{such that}&h_i(x) = 0,\ i=1,\dots,m;\\
&g_j(x) \le0,\ j=1,\dots,r
\end{array}
\end{equation}
\begin{theorem}[Karush, Kuhn, and Tucker]
Suppose that $x^*$ is an optimal solution to the problem~(\ref{Eq:4:3}), then under some \emph{regularity} condition (e.g., LICQ), there exists $\lambda\in\mathbb{R}^m$ and $\mu\in\mathbb{R}^r_+$ such that
\[
\left\{
\begin{aligned}
\nabla f(x^*)+\sum_{i=1}^m\lambda_i\nabla h_i(x^*)+\sum_{j=1}^r\mu_j\nabla g_j(x^*)&=0\\
\mu_jg_j(x^*)&=0,\ j=1,\dots,r.
\end{aligned}
\right.
\]
\end{theorem}

\subsection{The Lagrangian Dual Problem}
The KKT condition relates the explicit variable $x$ with the implicit variable $(\lambda,\mu)$. Now we take a close look at implicit variables, and they are called the \emph{Lagrangian multipliers}.

Define the Lagrangian function
\[
\mathcal{L}(x;\lambda,\mu):=f(x)+\sum_{i=1}^m\lambda_ih_i(x)+\sum_{j=1}^r\mu_jg_j(x),\ 
\mu_j\ge0.
\]

Let $d(\lambda,\mu) :=\min_{x}\mathcal{L}(x;\lambda,\mu)$, which implies the Lagrangian dual problem:
\begin{equation}\label{Eq:4:4}
\begin{array}{ll}
\max&d(\lambda,\mu)\\
\mbox{such that}&\lambda\in\mathbb{R}^m,\mu\in\mathbb{R}^r_+
\end{array}
\end{equation}

\subsection{Duality for conic optimization}
Consider the conic optimization problem
\[
\begin{array}{ll}
\min&\inp{\bm c}{\bm x}\\
\mbox{such that}&\bm{Ax}=\bm b\\
&\bm x\in\mathcal{K}
\end{array}
\]
its Lagrangian dual problem is
\[
\begin{array}{ll}
\max&\inp{\bm b}{\bm y}\\
\mbox{such that}&\bm A\trans\bm y+\bm s=\bm c\\
&\bm s\in\mathcal{K}^*
\end{array}
\]
Note that linear programming is a special conic optimization.

The conic optimization problem is commonly solved by simultaneously optimizing the primal and the dual problem, due to the duality theorem:
\begin{enumerate}
\item
Weak duality: any feasible primal solution value is an upper bound for any feasible dual solution value.
\item
Strong duality: under some conditions, i.e., for some special conic optimization problems such as LP, the primal optimal value coincides with the dual optimal value.
\end{enumerate} 

The dual variable are some hidden, implicit, potential quantities that are implied by the primal variables at the optimality. The \emph{optimality balance} is
\begin{equation}\label{Eq:4:5}
\left\{
\begin{aligned}
\bm{Ax}&=\bm b\\
\bm x&\in\mathcal{K}\\
\bm A\trans\bm y+\bm s&=\bm c\\
\bm s&\in\mathcal{K}^*\\
\inp{\bm x}{\bm s}&=0
\end{aligned}
\right.
\end{equation}

\section{Projection Problem}

Now we introduce a useful optimization problem, which can be applied to solve the system (\ref{Eq:4:5}):
\begin{equation}
\begin{array}{ll}
\min&\frac{1}{2}\|x-v\|^2\\
\mbox{such that}&x\in\mathcal{X}
\end{array}
\end{equation}
This problem is called the \emph{projection of $v$ onto the closed convex set $\mathcal{X}$}

\subsection{Projection onto the nonnegative orthant}
In particular, the problem is formulated as:
\begin{equation}
\begin{array}{ll}
\min&\frac{1}{2}\|x-v\|^2\\
\mbox{such that}&x\ge0.
\end{array}
\end{equation}
Therefore, the KKT condition is
\[
\left\{
\begin{aligned}
x-v-\mu&=0\\
x\ge0,\mu&\ge0,\inp{x}{\mu}=0
\end{aligned}
\right.
\]
In this case, the solution to the system above is
\[
\begin{array}{ll}
x=[v]_+,
&
\mu=-[v]_-
\end{array}
\]
The corresponding dual problem is
\[
\begin{array}{ll}
\max&-\frac{1}{2}\|\mu+v\|^2+\frac{1}{2}\|v\|^2\\
\mbox{such that}&\mu\ge0
\end{array}
\]

\paragraph{Check First Order Optimality Condition Directly}
Another way is to apply Theorem~(\ref{The:4:5}) directly:
\[
\mathcal{T}([v]_+) = \{d\mid d_i\ge0, i\in J\},\text{ where }J = \{i\mid v_i\le0\}.
\]
Since $\nabla\mid_{x=[v]_+}(\frac{1}{2}\|x-v\|^2) = [v]_+-v$, we have
\[
\inp{[v]_+-v}{d}\ge0,\ \forall d\in\mathcal{T}([v]_+).
\]
Therefore, by Theorem~(\ref{The:4:5}), $[v]_+$ is optimal to the nonnegative cone
projection problem.

\subsection{Projection onto the affine linear space $Ax=b$}
In particular, the problem is formulated as:
\begin{equation}
\begin{array}{ll}
\min&\frac{1}{2}\|x-v\|^2\\
\mbox{such that}&Ax=b.
\end{array}
\end{equation}
The solution for this problem is
\begin{align*}
x^* &= v + A\trans(AA\trans)^{-1})(b - Av)\\
&=(I - A\trans(AA\trans)^{-1}A)v + A\trans(AA\trans)^{-1}b\\
\lambda^*&=(AA\trans)^{-1}(b - Av)
\end{align*}
The solution is implied from the first order optimality condition:
\begin{align*}
\inp{\nabla f(x^*)}{d}&=\inp{x^*-v}{d}\\
&=(b-Av)\trans(AA\trans)^{-1}Ad\\
&=0,
\end{align*}
for any feasible direction $d\in\mathcal{T}(x^*)=\{d\mid Ad=0\}$.

\subsection{General Projection Problem}
Let $\mathcal{X}$ be a closed convex set and suppose $v\notin\mathcal{X}$. Consider
\begin{equation*}
\begin{array}{ll}
\min&\frac{1}{2}\|x-v\|^2\\
\mbox{such that}&x\in\mathcal{X}
\end{array}
\end{equation*}
Suppose that $x^*$ is the projection, i.e., optimal solution, then
\[
\inp{x^*-v}{x-x^*}\ge0,\ \forall x\in\mathcal{X}.
\]
Often, we denote the projection as $x^*=[v]_{\mathcal{X}}$.

\section{The Augmented Lagrangian Dual}
Now consider a more general optimization problem instead of projection:
\[
\begin{array}{ll}
\min&f(x)\\
\mbox{such that}&Ax=b\\
&x\in\mathcal{X}
\end{array}
\]
In projection problem we see that when the objective function involves the squared term, the optimization becomes easy becasue of the strong convexity of squared term. Therefore, we introduce an \emph{augmented Lagrangian function}
\[
\mathcal{L}_{\gamma}(x;\lambda)=f(x)+\lambda\trans(Ax-b)+\frac{\gamma}{2}\|Ax-b\|2,
\]
where $\gamma>0$ denotes the penality parameter. Like~(\ref{Eq:4:4}), define $d_\gamma(\lambda) = \min_{x\in\mathcal{X}}\mathcal{L}_{\gamma}(x;\lambda)$, and consider the dual problem
\begin{equation}\label{Eq:4:9}
\begin{array}{ll}
\max&d_\gamma(\lambda)\\
\mbox{such that}&\lambda\in\mathbb{R}^m
\end{array}
\end{equation}
question: what's this dual problem relates to the primal problem?

\begin{proposition}[Convexity]
$d_\gamma(\lambda)$ is concave in $\lambda$. Therefore the dual problem (\ref{Eq:4:9}) is always a convex optimization problem.
\end{proposition}
\begin{proof}
The dual function $h(y)=\min_{x}a(x)+y\trans b(x)$ is always concave in $y$. (question: do we need to specify that $\mathcal{X}$ is a convex set?)
\end{proof}

\begin{proposition}[Smooth]
$d_\gamma(\lambda)$ is differentiable in $\lambda$.
\end{proposition}
\begin{proof}
Note that $x_y\in \arg\min a(x)+y\trans b(x)$ implies $b(x_y)\in\partial h(y)$, since 
\[
h(y')\le h(y)+(y'-y)\trans b(x_y),\ \forall y'.
\]
Therefore, for $x_\lambda\in\arg\min f(x)+\lambda\trans(Ax-b)+\frac{\gamma}{2}\|Ax-b\|^2$, we have
\[
Ax_\lambda-b\in\partial d_\gamma(\lambda).
\]

To show the differentiablity suffices to show the uniqueness of the sub-gradient. Suppose there exists two solutions $x_\lambda'$ and $x_\lambda''$. By optimality condition,
\[
\left\{
\begin{aligned}
\inp{\nabla f(x_\lambda')+A\trans\lambda + \gamma A\trans(Ax'_\lambda-b)}{x_\lambda''-x_\lambda'}&\ge0,\\
\inp{\nabla f(x_\lambda'')+A\trans\lambda + \gamma A\trans(Ax''_\lambda-b)}{x_\lambda'-x_\lambda''}&\ge0
\end{aligned}
\right.
\]
Adding them up and noting that $\inp{\nabla f(x')-\nabla f(x'')}{x'-x''}\ge0$, we have
\[
Ax_\lambda'-b=Ax_{\lambda}''-b\implies \nabla d_\gamma(\lambda) = Ax_\lambda-b.
\]
\end{proof}

\begin{proposition}[Continuous differentiable]
$\nabla d_\gamma(\lambda)$ is Lipschitz continuous with a Lipschitz constant $1/\gamma$.
\end{proposition}
\begin{proof}
Let $\lambda'$ and $\lambda''$ be two vectors, similar as previous proof, we have:
\[
\left\{
\begin{aligned}
\inp{\nabla f(x_{\lambda'})+A\trans\lambda' + \gamma A\trans(Ax_{\lambda'}-b)}{x_{\lambda''}-x_{\lambda'}}&\ge0,\\
\inp{\nabla f(x_{\lambda''})+A\trans\lambda'' + \gamma A\trans(Ax_{\lambda''}-b)}{x_{\lambda'}-x_{\lambda''}}&\ge0
\end{aligned}
\right.
\]
Adding them up, we have
\[
\gamma\|A(x_{\lambda''}-x_{\lambda'})\|^2\le(\lambda'-\lambda'')\trans A(x_{\lambda''}-x_{\lambda'})
\]
By Cauchy-Schwarz inequality,
\[
\|\nabla d_{\gamma}(\lambda') - \nabla d_\gamma(\lambda'')\|\le\frac{1}{\gamma}\|\lambda'-\lambda''\|.
\]
\end{proof}















